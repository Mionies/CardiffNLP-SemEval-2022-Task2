{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92b1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e4f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSV2Json(c):\n",
    "    heads = c[0]\n",
    "    j = []\n",
    "    for x in c[1:]:\n",
    "        d = {}\n",
    "        for i,y in enumerate(x):\n",
    "            d[heads[i]]=y\n",
    "        j.append(d)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb793a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SubTaskA/Data/train_zero_shot.csv\", newline='',encoding='utf8') as csvfile:\n",
    "    gut = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    train_zero = list(gut)\n",
    "    \n",
    "#with open(\"SubtaskA/TestData/train_one_shot.csv\", newline='',encoding='utf8') as csvfile:\n",
    "#    gut = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "#    train_one_test = list(gut)\n",
    "    \n",
    "with open(\"SubTaskA/Data/train_one_shot.csv\", newline='',encoding='utf8') as csvfile:\n",
    "    gut = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    train_one = list(gut)\n",
    "    \n",
    "with open(\"SubTaskA/Data/dev.csv\", newline='',encoding='utf8') as csvfile:\n",
    "    gut = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    devset = list(gut)\n",
    "    \n",
    "with open(\"SubTaskA/Data/dev_gold.csv\", newline='',encoding='utf8') as csvfile:\n",
    "    gut = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    devset_gold = list(gut)\n",
    "\n",
    "with open(\"SubTaskA/Data/dev_submission_format.csv\", newline='',encoding='utf8') as csvfile:\n",
    "    gut = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    devset_sub = list(gut)\n",
    "    \n",
    "with open(\"SubTaskA/Data/eval.csv\", newline='',encoding='utf8') as csvfile:\n",
    "    gut = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    evalset = list(gut)\n",
    "    \n",
    "with open(\"SubTaskA/Data/eval_submission_format.csv\", newline='',encoding='utf8') as csvfile:\n",
    "    gut = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    evalset_sub = list(gut)\n",
    "    \n",
    "with open(\"SubTaskA/TestData/test_submission_format.csv\", newline='',encoding='utf8') as csvfile:\n",
    "    gut = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    testset_sub = list(gut)\n",
    "    \n",
    "with open(\"SubTaskA/TestData/test.csv\", newline='',encoding='utf8') as csvfile:\n",
    "    gut = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    testset = list(gut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19446f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train_zero = CSV2Json(train_zero)\n",
    "csv_train_one = CSV2Json(train_one)\n",
    "#csv_train_one_dev_eval= CSV2Json(train_one_dev_eval)\n",
    "csv_dev = CSV2Json(devset)\n",
    "csv_devgold = CSV2Json(devset_gold)\n",
    "csv_eval = CSV2Json(evalset)\n",
    "csv_test = CSV2Json(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b9b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "semdev = []\n",
    "semeval = []\n",
    "semtest = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "832470c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4491\n"
     ]
    }
   ],
   "source": [
    "semtrain0 = []\n",
    "n = 0\n",
    "er=0\n",
    "for x in csv_train_zero:\n",
    "    w = {\"additionalInformation\":{\"context\":{\"nextSentence\":x[\"Next\"],\"previousSentence\":x[\"Previous\"]}},\"id\":x[\"DataID\"],\"corpus\":\"SemevalZeroShot\"}\n",
    "    w[\"context\"]=x[\"Target\"]\n",
    "    w[\"expression\"]=x[\"MWE\"]\n",
    "    w[\"label\"]=x[\"Label\"]\n",
    "    w[\"position\"]=[]\n",
    "    w[\"additionalInformation\"][\"language\"]=x[\"Language\"]\n",
    "    w[\"additionalInformation\"][\"setting\"]=x[\"Setting\"]\n",
    "    w[\"additionalInformation\"][\"semID\"]=x[\"DataID\"]\n",
    "    w[\"additionalInformation\"]['broadContext']=\" \".join([x[\"Previous\"],x[\"Target\"],x[\"Next\"]])\n",
    "    patter = re.split(\" |-\",w[\"expression\"].lower())\n",
    "    patter = \"[ -]\".join(patter)\n",
    "    sentence = w[\"context\"].lower()\n",
    "    paragraph = w[\"additionalInformation\"]['broadContext'].lower()\n",
    "    posi = []\n",
    "    posi_long = []\n",
    "    for match in re.finditer(patter, sentence):\n",
    "        posi.append(match.span())\n",
    "    for match in re.finditer(patter, paragraph):\n",
    "        posi_long.append(match.span())\n",
    "    if len(posi)==0:\n",
    "        if w[\"expression\"] == \"efeito especial\":\n",
    "            patter = re.split(\" |-\",\"efeitos especiais\")\n",
    "            patter = \"[ -]\".join(patter)\n",
    "            for match in re.finditer(patter, sentence):\n",
    "                posi.append(match.span())\n",
    "            for match in re.finditer(patter, paragraph):\n",
    "                posi_long.append(match.span())\n",
    "        elif w[\"expression\"]==\"círculo virtuoso\":\n",
    "            patter = re.split(\" |-\",\"circulo virtuoso\")\n",
    "            patter = \"[ -]\".join(patter)\n",
    "            for match in re.finditer(patter, sentence):\n",
    "                posi.append(match.span())\n",
    "            for match in re.finditer(patter, paragraph):\n",
    "                posi_long.append(match.span())\n",
    "        elif w[\"expression\"]==\"paraíso fiscal\":\n",
    "            patter = re.split(\" |-\",\"paraísos fiscais\")\n",
    "            patter = \"[ -]\".join(patter)\n",
    "            for match in re.finditer(patter, sentence):\n",
    "                posi.append(match.span())\n",
    "            for match in re.finditer(patter, paragraph):\n",
    "                posi_long.append(match.span())\n",
    "        if len(posi)==0:\n",
    "            print(c,w[\"expression\"],w[\"context\"])\n",
    "            er+=1     \n",
    "        if len(posi_long)==0:\n",
    "            print(c,\"long\",w[\"expression\"],w[\"context\"])\n",
    "            er+=1     \n",
    "    w[\"position\"]=posi\n",
    "    w[\"additionalInformation\"]['positionBroadContext']=posi_long\n",
    "    w[\"additionalInformation\"][\"firstPositionBroadContext\"]=[posi[0][0]+len(x[\"Previous\"])+1,posi[0][1]+len(x[\"Previous\"])+1]\n",
    "    w[\"dataSplit\"]=\"train\"\n",
    "    w[\"expression_cased\"]=w[\"additionalInformation\"][\"broadContext\"][w[\"additionalInformation\"][\"firstPositionBroadContext\"][0]:w[\"additionalInformation\"][\"firstPositionBroadContext\"][1]]\n",
    "    semtrain0.append(w)\n",
    "    n+=1\n",
    "    \n",
    "        \n",
    "print(er,len(semtrain0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692ca5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 140\n"
     ]
    }
   ],
   "source": [
    "semtrain1 = []\n",
    "n = 0\n",
    "er=0\n",
    "for x in csv_train_one:\n",
    "    w = {\"additionalInformation\":{\"context\":{\"nextSentence\":x[\"Next\"],\"previousSentence\":x[\"Previous\"]}},\"id\":x[\"DataID\"],\"corpus\":\"SemevalZeroShot\"}\n",
    "    w[\"context\"]=x[\"Target\"]\n",
    "    w[\"expression\"]=x[\"MWE\"]\n",
    "    w[\"label\"]=x[\"Label\"]\n",
    "    w[\"additionalInformation\"][\"language\"]=x[\"Language\"]\n",
    "    w[\"additionalInformation\"][\"setting\"]=x[\"Setting\"]\n",
    "    w[\"additionalInformation\"][\"semID\"]=x[\"DataID\"]\n",
    "    w[\"additionalInformation\"]['broadContext']=\" \".join([x[\"Previous\"],x[\"Target\"],x[\"Next\"]])\n",
    "    patter = re.split(\" |-\",w[\"expression\"].lower())\n",
    "    patter = \"[ -]\".join(patter)\n",
    "    sentence = w[\"context\"].lower()\n",
    "    paragraph = w[\"additionalInformation\"]['broadContext'].lower()\n",
    "    posi = []\n",
    "    posi_long = []\n",
    "    for match in re.finditer(patter, paragraph):\n",
    "        posi_long.append(match.span())\n",
    "    for match in re.finditer(patter, sentence):\n",
    "        posi.append(match.span())\n",
    "    if len(posi)==0:\n",
    "        print(c,w[\"expression\"],w[\"context\"])\n",
    "        er+=1\n",
    "    #posi = w[\"context\"].index(w[\"expression\"])\n",
    "    #w[\"position\"]=[posi,posi+len(w[\"expression\"])]\n",
    "    w[\"position\"]=posi\n",
    "    w[\"additionalInformation\"]['positionBroadContext']=posi_long\n",
    "    w[\"additionalInformation\"][\"firstPositionBroadContext\"]=[posi[0][0]+len(x[\"Previous\"])+1,posi[0][1]+len(x[\"Previous\"])+1]\n",
    "    w[\"dataSplit\"]=\"train\"\n",
    "    w[\"expression_cased\"]=w[\"additionalInformation\"][\"broadContext\"][w[\"additionalInformation\"][\"firstPositionBroadContext\"][0]:w[\"additionalInformation\"][\"firstPositionBroadContext\"][1]]\n",
    "    semtrain1.append(w)\n",
    "    n+=1\n",
    "    \n",
    "        \n",
    "print(er,len(semtrain1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebaffcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 739\n"
     ]
    }
   ],
   "source": [
    "semdev = []\n",
    "\n",
    "n = 0\n",
    "er=0\n",
    "for i,x in enumerate(csv_dev):\n",
    "    w = {\"additionalInformation\":{\"context\":{\"nextSentence\":x[\"Next\"],\"previousSentence\":x[\"Previous\"]}},\"id\":csv_devgold[i][\"DataID\"],\"corpus\":\"SemevalTaskA\"}\n",
    "    w[\"context\"]=x[\"Target\"]\n",
    "    w[\"expression\"]=x[\"MWE\"]\n",
    "    w[\"label\"]=csv_devgold[i][\"Label\"]\n",
    "    w[\"additionalInformation\"][\"semID\"]=csv_devgold[i][\"ID\"]\n",
    "    w[\"additionalInformation\"][\"language\"]=csv_devgold[i][\"Language\"]\n",
    "    w[\"additionalInformation\"]['broadContext']=\" \".join([x[\"Previous\"],x[\"Target\"],x[\"Next\"]])\n",
    "    w[\"dataSplit\"]=\"dev\"\n",
    "    patter = re.split(\" |-\",w[\"expression\"].lower())\n",
    "    patter = \"[ -]\".join(patter)\n",
    "    sentence = w[\"context\"].lower()\n",
    "    paragraph = w[\"additionalInformation\"]['broadContext'].lower()\n",
    "    posi = []\n",
    "    posi_long = []\n",
    "    for match in re.finditer(patter, sentence):\n",
    "        posi.append(match.span())\n",
    "    for match in re.finditer(patter, paragraph):\n",
    "        posi_long.append(match.span())\n",
    "    if len(posi)==0:\n",
    "        print(c,w[\"expression\"],w[\"context\"])\n",
    "        er+=1\n",
    "    w[\"position\"]=posi\n",
    "    w[\"additionalInformation\"]['positionBroadContext']=posi_long\n",
    "    w[\"additionalInformation\"][\"firstPositionBroadContext\"]=[posi[0][0]+len(x[\"Previous\"])+1,posi[0][1]+len(x[\"Previous\"])+1]\n",
    "    w[\"dataSplit\"]=\"dev\"\n",
    "    w[\"expression_cased\"]=w[\"additionalInformation\"][\"broadContext\"][w[\"additionalInformation\"][\"firstPositionBroadContext\"][0]:w[\"additionalInformation\"][\"firstPositionBroadContext\"][1]]\n",
    "    semdev.append(w)\n",
    "    n+=1\n",
    "    \n",
    "        \n",
    "print(er,len(semdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8383a52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 762\n"
     ]
    }
   ],
   "source": [
    "semeval = []\n",
    "\n",
    "\n",
    "n = 0\n",
    "er=0\n",
    "for x in csv_eval:\n",
    "    w = {\"additionalInformation\":{\"context\":{\"nextSentence\":x[\"Next\"],\"previousSentence\":x[\"Previous\"]}},\"id\":\"eval\"+str(x[\"ID\"]),\"corpus\":\"SemevalTaskA\"}\n",
    "    w[\"context\"]=x[\"Target\"]\n",
    "    w[\"expression\"]=x[\"MWE\"]\n",
    "    w[\"additionalInformation\"][\"language\"]=x[\"Language\"]\n",
    "    w[\"additionalInformation\"][\"semID\"]=x[\"ID\"]\n",
    "    w[\"additionalInformation\"]['broadContext']=\" \".join([x[\"Previous\"],x[\"Target\"],x[\"Next\"]])\n",
    "    w[\"dataSplit\"]=\"eval\"\n",
    "    patter = re.split(\" |-\",w[\"expression\"].lower())\n",
    "    patter = \"[ -]\".join(patter)\n",
    "    sentence = w[\"context\"].lower()\n",
    "    paragraph =  w[\"additionalInformation\"]['broadContext'].lower()\n",
    "    posi,posi_long = [],[]\n",
    "    for match in re.finditer(patter, sentence):\n",
    "        posi.append(match.span())\n",
    "    for match in re.finditer(patter, paragraph):\n",
    "        posi_long.append(match.span())\n",
    "    if len(posi)==0:\n",
    "        if w[\"expression\"] == \"núcleo atômico\":\n",
    "            patter = re.split(\" |-\",\"núcleos atômicos\")\n",
    "            patter = \"[ -]\".join(patter)\n",
    "            for match in re.finditer(patter, sentence):\n",
    "                posi.append(match.span())      \n",
    "            for match in re.finditer(patter, paragraph):\n",
    "                posi_long.append(match.span())\n",
    "        if len(posi)==0:\n",
    "            print(c,w[\"expression\"],w[\"context\"])\n",
    "            er+=1\n",
    "    w[\"additionalInformation\"]['positionBroadContext']=posi_long\n",
    "    w[\"position\"]=posi\n",
    "    w[\"additionalInformation\"][\"firstPositionBroadContext\"]=[posi[0][0]+len(x[\"Previous\"])+1,posi[0][1]+len(x[\"Previous\"])+1]\n",
    "    w[\"dataSplit\"]=\"eval\"\n",
    "    w[\"expression_cased\"]=w[\"additionalInformation\"][\"broadContext\"][w[\"additionalInformation\"][\"firstPositionBroadContext\"][0]:w[\"additionalInformation\"][\"firstPositionBroadContext\"][1]]\n",
    "    semeval.append(w)\n",
    "    n+=1\n",
    "    if len(w[\"additionalInformation\"][\"positionBroadContext\"])==0:\n",
    "        print(posi, posi_long)\n",
    "        \n",
    "print(er,len(semeval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a0eaa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2342\n"
     ]
    }
   ],
   "source": [
    "semtest = []\n",
    "#test ['ID', 'Language', 'MWE', 'Previous', 'Target', 'Next']\n",
    "\n",
    "n = 0\n",
    "er=0\n",
    "for x in csv_test:\n",
    "    w = {\"additionalInformation\":{\"context\":{\"nextSentence\":x[\"Next\"],\"previousSentence\":x[\"Previous\"]}},\"id\":\"test.\"+str(x[\"ID\"]),\"corpus\":\"SemevalTaskA\"}\n",
    "    w[\"context\"]=x[\"Target\"]\n",
    "    w[\"expression\"]=x[\"MWE\"]\n",
    "    w[\"additionalInformation\"][\"language\"]=x[\"Language\"]\n",
    "    w[\"additionalInformation\"][\"semID\"]=x[\"ID\"]\n",
    "    w[\"additionalInformation\"]['broadContext']=\" \".join([x[\"Previous\"],x[\"Target\"],x[\"Next\"]])\n",
    "    w[\"dataSplit\"]=\"test\"\n",
    "    patter = re.split(\" |-\",w[\"expression\"].lower())\n",
    "    patter = \"[ -]\".join(patter)\n",
    "    sentence = w[\"context\"].lower()\n",
    "    paragraph =w[\"additionalInformation\"]['broadContext'].lower()\n",
    "    posi,posi_long = [],[]\n",
    "    for match in re.finditer(patter, sentence):\n",
    "        posi.append(match.span())\n",
    "    for match in re.finditer(patter, paragraph):\n",
    "        posi_long.append(match.span())\n",
    "    if len(posi_long)==0:\n",
    "        print(w[\"expression\"],w[\"paragraph\"])\n",
    "        er+=1\n",
    "    w[\"additionalInformation\"]['positionBroadContext']=posi_long\n",
    "    w[\"additionalInformation\"][\"firstPositionBroadContext\"]=[posi[0][0]+len(x[\"Previous\"])+1,posi[0][1]+len(x[\"Previous\"])+1]\n",
    "    w[\"position\"]=posi\n",
    "    w[\"dataSplit\"]=\"test\"\n",
    "    w[\"expression_cased\"]=w[\"additionalInformation\"][\"broadContext\"][w[\"additionalInformation\"][\"firstPositionBroadContext\"][0]:w[\"additionalInformation\"][\"firstPositionBroadContext\"][1]]\n",
    "    semtest.append(w)\n",
    "    n+=1\n",
    "    \n",
    "        \n",
    "print(er,len(semtest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f108cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4491\n",
      "140\n",
      "739\n",
      "762\n",
      "2342\n"
     ]
    }
   ],
   "source": [
    "print(len(semtrain0))\n",
    "print(len(semtrain1))\n",
    "#len(semtrain1_dev_eval)\n",
    "print(len(semdev))\n",
    "print(len(semeval))\n",
    "print(len(semtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d351c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(semtrain0)\n",
    "#random.shuffle(semtrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "700a3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval_all = {\"semevalZeroShot\":[],\"semevalOneShot\":[]}\n",
    "\n",
    "for x in semtrain0:\n",
    "    i = copy.deepcopy(x)\n",
    "    i[\"corpus\"]=\"semevalZeroShot\"\n",
    "    semeval_all[\"semevalZeroShot\"].append(i)\n",
    "    j = copy.deepcopy(x)\n",
    "    j[\"corpus\"]=\"semevalOneShot\"\n",
    "    semeval_all[\"semevalOneShot\"].append(j)\n",
    "\n",
    "    \n",
    "for x in semtrain1:\n",
    "    i = copy.deepcopy(x)\n",
    "    i[\"corpus\"]=\"semevalOneShot\"\n",
    "    semeval_all[\"semevalOneShot\"].append(i)\n",
    "    \n",
    "for x in semdev:\n",
    "    i = copy.deepcopy(x)\n",
    "    i[\"corpus\"]=\"semevalOneShot\"\n",
    "    semeval_all[\"semevalOneShot\"].append(i)\n",
    "    j = copy.deepcopy(x)\n",
    "    j[\"corpus\"]=\"semevalZeroShot\"\n",
    "    semeval_all[\"semevalZeroShot\"].append(j)\n",
    "  \n",
    "for x in semeval:\n",
    "    i = copy.deepcopy(x)\n",
    "    i[\"corpus\"]=\"semevalOneShot\"\n",
    "    semeval_all[\"semevalOneShot\"].append(i)\n",
    "    j = copy.deepcopy(x)\n",
    "    j[\"corpus\"]=\"semevalZeroShot\"\n",
    "    semeval_all[\"semevalZeroShot\"].append(j)\n",
    "\n",
    "\n",
    "for x in semtest:\n",
    "    i = copy.deepcopy(x)\n",
    "    i[\"corpus\"]=\"semevalOneShot\"\n",
    "    semeval_all[\"semevalOneShot\"].append(i)\n",
    "    j = copy.deepcopy(x)\n",
    "    j[\"corpus\"]=\"semevalZeroShot\"\n",
    "    semeval_all[\"semevalZeroShot\"].append(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9439a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(semeval_all[\"semevalZeroShot\"])\n",
    "random.shuffle(semeval_all[\"semevalOneShot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7f57735",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('semevalTaskA_shuffle.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(semeval_all, file, indent='\\t', ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
